{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f603e8eb-aefb-43d8-866e-9b857f8ca864",
   "metadata": {},
   "source": [
    "# Example: Rock Paper Scissors Game Simulation\n",
    "Rock, paper, and scissors is a simple zero-sum game in which two players simultaneously play `rock`, `paper`, or `scissors`. When a player wins a round of rock, paper, or scissors, they are awarded `+1`. However, if they lose the game, they receive a `-1` reward. Rules:\n",
    "* `Rock` beats `scissors` but loses to `paper`\n",
    "* `Paper` beats `rock` but loses to `scissors`\n",
    "* `Scissors` beats `paper` but loses to `rock`\n",
    "\n",
    "### Learning objectives\n",
    "The objective of this example is to familiarize students with simple zero-sum games, e.g., Rock, Paper and Scissors, and in particular, the implementation and ideas for exploring these games found in the `Decisions` book:\n",
    "\n",
    "* [Algorithms For Decision Making, Kochenderfer, Wheeler, Wray, MIT Press, 2022](https://algorithmsbook.com)\n",
    "\n",
    "We've implemented some of the codes found in `Chapter 24` of the `Decisions` book in our package [VLDecisionsPackage.jl](https://github.com/varnerlab/VLDecisionsPackage.jl.git)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9292d8-b661-46fa-912c-db8697a8a0db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "Let's load some packages that are required for the example by calling the `include(...)` function on our initialization file `Include.jl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5470aa8d-a3f0-41d3-a910-1a7b84a2b32a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Desktop/julia_work/CHEME-5760-Examples-F23/Project.toml`\n",
      "  \u001b[90m[10f378ab] \u001b[39m\u001b[93m~ VLDecisionsPackage v0.1.0 `https://github.com/varnerlab/VLDecisionsPackage.jl.git#main` ⇒ v0.1.0 `https://github.com/varnerlab/VLDecisionsPackage.jl.git#main`\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Desktop/julia_work/CHEME-5760-Examples-F23/Manifest.toml`\n",
      "  \u001b[90m[10f378ab] \u001b[39m\u001b[93m~ VLDecisionsPackage v0.1.0 `https://github.com/varnerlab/VLDecisionsPackage.jl.git#main` ⇒ v0.1.0 `https://github.com/varnerlab/VLDecisionsPackage.jl.git#main`\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mVLDecisionsPackage\n",
      "  1 dependency successfully precompiled in 4 seconds. 226 already precompiled.\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-5760-Examples-F23`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Examples-F23/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Examples-F23/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257dad57-42a7-45e4-b59e-de930361713d",
   "metadata": {},
   "source": [
    "### Types\n",
    "This example will use two new types.\n",
    "\n",
    "The `MySimpleGameModel` encodes data about simple games in the fields:\n",
    "* The `γ::Float64` holds the discount factor, which describes how much we care about current moves compared with potential future moves\n",
    "* The `ℐ::Array{Int64,1}` field holds the indexes of the players of the game\n",
    "* The `𝒜` field holds the joint action space of the game\n",
    "* The `R` field holds the joint reward function of the game\n",
    "\n",
    "The `MySimpleGamePolicy` type holds information about the policy used by a player in a game, this type has one important field:\n",
    "* The `p::Dict{Symbol,Float64}` field is a `Dictionary` which holds the probability of an action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c46a76-7674-4dc8-b01b-4b5048bb4f59",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Before we begin playing the game, we setup several helper functions that we use to initialize the game, and use throughout the game during the game play. First, the `number_of_agents(simpleGame::MySimpleGameModel) = 2` method takes a `MySimpleGameModel` model as an argument and returns the number of players of the game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0404fd8b-0fdb-49a7-8b7d-ff68e1cdc8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_agents(simpleGame::MySimpleGameModel) = 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d140bd-6385-4f91-83d9-b7ccb6a55783",
   "metadata": {},
   "source": [
    "Next, the `ordered_actions(simpleGame::MySimpleGameModel, i::Int) = [:rock, :paper, :scissors]` method takes a `MySimpleGameModel` instance, a player index `i` and returns the an array of actions that are open to the player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cab815-2e18-414b-88b5-f4f9ca16c842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_actions(simpleGame::MySimpleGameModel, i::Int) = [:rock, :paper, :scissors];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27690cf-c3ad-4cbe-889a-a4e25b18ef5f",
   "metadata": {},
   "source": [
    "The `reward(simpleGame::MySimpleGameModel, i::Int, a)` function takes a `MySimpleGameModel` instance, a player index `i` and a joint action `a::Tuple{Symbol,Symbol}` and returns back the reward for that round of game play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23deeedd-9082-4482-99db-b03bbb4cde48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reward (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reward(simpleGame::MySimpleGameModel, i::Int, a)\n",
    "    if i == 1\n",
    "        noti = 2\n",
    "    else\n",
    "        noti = 1\n",
    "    end\n",
    "\n",
    "    if a[i] == a[noti]\n",
    "        r = 0.0\n",
    "    elseif a[i] == :rock && a[noti] == :paper\n",
    "        r = -1.0\n",
    "    elseif a[i] == :rock && a[noti] == :scissors\n",
    "        r = 1.0\n",
    "    elseif a[i] == :paper && a[noti] == :rock\n",
    "        r = 1.0\n",
    "    elseif a[i] == :paper && a[noti] == :scissors\n",
    "        r = -1.0\n",
    "    elseif a[i] == :scissors && a[noti] == :rock\n",
    "        r = -1.0\n",
    "    elseif a[i] == :scissors && a[noti] == :paper\n",
    "        r = 1.0\n",
    "    end\n",
    "\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a4322-a03c-434f-98a2-3ee9974c9a85",
   "metadata": {},
   "source": [
    "Finally, the `joint_reward(simpleGame::MySimpleGameModel, a)` function takes a `MySimpleGameModel` instance, and a joint action `a` and returns the reward array for that joint action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93e6a58-0ad1-4baf-8fd6-85ad0ce6e99d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_reward (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function joint_reward(simpleGame::MySimpleGameModel, a)\n",
    "    return [reward(simpleGame, i, a) for i in 1:number_of_agents(simpleGame)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a191b7-808e-44f2-87d9-86200407511f",
   "metadata": {},
   "source": [
    "## Rock, paper and Scissors Game setup\n",
    "Let's build and populate (manually) an instance of the game object, which is type `MySimpleGameModel()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce67d43-cede-4f4a-9939-f9084845f06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mysimplegame = MySimpleGameModel();\n",
    "mysimplegame.γ = 0.9;\n",
    "mysimplegame.ℐ = [1,2];\n",
    "mysimplegame.𝒜 = [ordered_actions(mysimplegame, i) for i in 1:number_of_agents(mysimplegame)]\n",
    "mysimplegame.R = (a) -> joint_reward(mysimplegame, a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42eba9-0b96-43de-8206-0eec7098f946",
   "metadata": {},
   "source": [
    "Next, we setup our policies for each player. These policies are type `Dict` that hold the action, e.g., `:rock` as `keys` which point to probability values. We assign these to the `π₁` and `π₂` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee2884b-a581-4800-a0fa-06696d1f07bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "π₁ = MySimpleGamePolicy(Dict(:rock => 0.6, :paper => 0.2, :scissors => 0.2));\n",
    "π₂ = MySimpleGamePolicy(Dict(:rock => 0.2, :paper => 0.7, :scissors => 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e53f1-f695-4346-a80c-5bf85c2ed1cc",
   "metadata": {},
   "source": [
    "Finally, we construct the _joint policy_ which holds the policies for each of the players:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044d46cc-29f0-4567-a106-ac586955623e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "π = [π₁ ; π₂];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e93a6a-bbc7-44a0-b371-2efd3c3f23a0",
   "metadata": {},
   "source": [
    "## Compute the Best Deterministic Response\n",
    "The _deterministic best response_ of agent $i$ to the policies of the other agents $\\pi^{-i}$ is a policy $\\pi^{i}$ that\n",
    "satisfies:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    U^{i}(\\pi^{i}, \\pi^{-i}) \\geq U^{i}(\\pi^{i\\prime}, \\pi^{-i}) \\quad \\forall \\pi^{i\\prime} \\neq \\pi^{i}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ec44d2-0e17-4825-87ca-2cf91fb5cede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, MySimpleGamePolicy} with 2 entries:\n",
       "  2 => MySimpleGamePolicy(Dict(:paper=>1.0))\n",
       "  1 => MySimpleGamePolicy(Dict(:scissors=>1.0))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_deterministic_policy = Dict{Int64, MySimpleGamePolicy}()\n",
    "for i ∈ 1:number_of_agents(mysimplegame)\n",
    "    best_deterministic_policy[i] = best_response_policy(mysimplegame,π,i);\n",
    "end\n",
    "best_deterministic_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe01323e-375a-4287-85f4-0fcd626e0d5b",
   "metadata": {},
   "source": [
    "## Compute the Best Softmax Response\n",
    "The _softmax response model_ to compute the action $a^{i}$ is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\pi^{i}(a^{i}) \\sim \\exp(\\lambda\\cdot{U}^{i}(a^{i}, \\pi^{-i}))\n",
    "\\end{equation*} \n",
    "$$\n",
    "\n",
    "The parameter $\\lambda$ determines the degree of rationality: $\\lambda \\rightarrow 0$, the agent becomes random, while $\\lambda \\rightarrow \\infty$, the agent becomes perfectly rational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e690462d-25a3-4d93-b87e-a3f0f5414d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, MySimpleGamePolicy} with 2 entries:\n",
       "  2 => MySimpleGamePolicy(Dict(:scissors=>0.00032932, :rock=>0.0179803, :paper=…\n",
       "  1 => MySimpleGamePolicy(Dict(:scissors=>0.00032932, :rock=>0.0179803, :paper=…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_softmax_policy = Dict{Int64, MySimpleGamePolicy}()\n",
    "for i ∈ 1:number_of_agents(mysimplegame)\n",
    "    best_softmax_policy[i] = softmax_response_policy(mysimplegame, π, 2, 10.0);\n",
    "end\n",
    "best_softmax_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711897d0-549f-4a2d-bfa6-32bc14f48d70",
   "metadata": {},
   "source": [
    "## Compute the Best Hierarchical Softmax Policy\n",
    "The _Hierarchical softmax response model_ simulates the _depth of rationality_ of an agent by a level parameter $k\\geq{0}$, along with the softmax $\\lambda$ parameter:\n",
    "\n",
    "* A level `k = 0` agent selects actions from the initial policy\n",
    "* A level `k = 1` agent selects actions according to the _softmax response model_ using parameter $\\lambda$.\n",
    "* A level `k ≥ 2` agent selects actions according to a _softmax response model_ model of other players playing at $k-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f097e71f-1241-45fa-ac7e-51c57de9e4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyHierarchicalSoftmaxPolicy(5.0, 0, MySimpleGamePolicy[MySimpleGamePolicy(Dict(:scissors => 0.2, :rock => 0.6, :paper => 0.2)), MySimpleGamePolicy(Dict(:scissors => 0.1, :rock => 0.2, :paper => 0.7))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ = 5.0\n",
    "k = 0\n",
    "hierarchical_softmax_policy = MyHierarchicalSoftmaxPolicy(λ, k, π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0663012a-22e9-4a88-9f00-93b8de654505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{MySimpleGamePolicy}:\n",
       " MySimpleGamePolicy(Dict(:scissors => 0.2, :rock => 0.6, :paper => 0.2))\n",
       " MySimpleGamePolicy(Dict(:scissors => 0.1, :rock => 0.2, :paper => 0.7))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = solve(hierarchical_softmax_policy, mysimplegame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e6be9-ca51-45bf-b416-a3cf70bc5e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
